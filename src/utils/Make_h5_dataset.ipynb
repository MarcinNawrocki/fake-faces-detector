{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Make_h5_dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyNAzn+az5/t7nOrk5eWIYVO"},"kernelspec":{"name":"python3","display_name":"Python 3.7.9 64-bit ('TF_gpu': conda)"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"0991d9f816f3ae08431cbfe77283594d685f9351f97c7a8199c52bebed5a8c9f"}},"cells":[{"cell_type":"code","execution_count":1,"source":["import os\r\n","from PIL import Image\r\n","import random\r\n","\r\n","import h5py\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from db_helper import get_files_paths_recursive"],"outputs":[],"metadata":{"id":"3MOgtxRHq-l2","executionInfo":{"status":"ok","timestamp":1618476464024,"user_tz":-120,"elapsed":602,"user":{"displayName":"Marcin Nawrocki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWNgsnwLeRdQhCdvgSiWdtmpF5uLrNe1NL5s4uAw=s64","userId":"11241534018470902834"}}}},{"cell_type":"code","execution_count":2,"source":["categories_and_paths = {0: R\"F:\\master-thesis-databases\\classification_db\\fake\", \r\n","                        1 :R\"F:\\master-thesis-databases\\classification_db\\real\"}\r\n","result_dir = R\"C:\\Users\\Marcin\\Dysk Google\\masterDB\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["def load_dataset_h5(path, dataset_name):\r\n","    with h5py.File(path, \"r\") as hf:\r\n","        print(hf.keys())\r\n","        X = hf[dataset_name][:]\r\n","        hf.close()\r\n","    return X"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["def convert_images_to_h5(img_paths, h5_path, dataset_name, img_in_cycle):\r\n","    print(f\"Saving images as {dataset_name}\")\r\n","    img_list = []\r\n","    i=0\r\n","    for img_path in img_paths:\r\n","        if i % 100 == 0:\r\n","            print(f\"Image number: {i}\")\r\n","        i += 1\r\n","        # loading images \r\n","        pil_image = Image.open(img_path)\r\n","        np_image = np.array(pil_image).astype((np.uint8))\r\n","        img_list.append(np_image)\r\n","        # saving to h5 file\r\n","        if i % img_in_cycle == 0 and i > 0:\r\n","            # h5 dataset creation\r\n","            np_img_list = np.asarray(img_list)\r\n","            #TODO maybe some static function\r\n","            if i == img_in_cycle:\r\n","                with h5py.File(h5_path, 'w') as hf:\r\n","                    #images\r\n","                    hf.create_dataset(dataset_name, \r\n","                                    np_img_list.shape, \r\n","                                    data=np_img_list,\r\n","                                    maxshape=((None,)+np_img_list.shape[1:]),\r\n","                                    chunks=True)\r\n","            # h5 dataset append\r\n","            else:\r\n","                with h5py.File(h5_path, \"a\") as hf:\r\n","                    hf[dataset_name].resize(i, axis=0)\r\n","                    hf[dataset_name][-img_in_cycle:] = np.asarray(img_list)\r\n","                    hf.close()   \r\n","            img_list.clear()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["def convert_dataset_to_h5(img_paths, img_categories, h5_path, dataset_name, img_in_cycle=10):\r\n","    print(f\"To {h5_path} for dataset:{dataset_name}\")\r\n","    assert len(img_paths) > img_in_cycle, \"Database to small for specified saving cycle\"\r\n","\r\n","    if os.path.exists(h5_path):\r\n","        os.remove(h5_path)\r\n","    X_dataset_name = 'X_' + dataset_name\r\n","    y_dataset_name = 'y_' + dataset_name \r\n","\r\n","    # add images\r\n","    convert_images_to_h5(img_paths, h5_path, X_dataset_name, img_in_cycle=img_in_cycle)\r\n","    # add categories\r\n","    np_img_categories = np.asarray(img_categories)\r\n","    with h5py.File(h5_path, 'a') as hf:\r\n","        #images\r\n","        hf.create_dataset(y_dataset_name, \r\n","                        np_img_categories.shape, \r\n","                        data=np_img_categories,\r\n","                        maxshape=np_img_categories.shape)"],"outputs":[],"metadata":{"id":"i2Uk2KTerWWU","executionInfo":{"status":"ok","timestamp":1618476590958,"user_tz":-120,"elapsed":712,"user":{"displayName":"Marcin Nawrocki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWNgsnwLeRdQhCdvgSiWdtmpF5uLrNe1NL5s4uAw=s64","userId":"11241534018470902834"}}}},{"cell_type":"code","execution_count":6,"source":["def make_dataset_for_keras_h5(categories, result_directory, split_factor=0.8):\r\n","    print(f\"Make dataset from: {categories} to {result_directory}\")\r\n","    flag='w'\r\n","    train_path = os.path.join(result_directory, 'train.h5')\r\n","    val_path = os.path.join(result_directory, 'val.h5')\r\n","    img_paths_and_categories = []\r\n","    for name, path in categories.items():\r\n","        img_paths_and_categories += get_files_paths_recursive(path, category=name)[:5000]\r\n","    # create shuffled lists\r\n","    random.shuffle(img_paths_and_categories)\r\n","    img_paths = [path for path, category in img_paths_and_categories]\r\n","    img_categories = [category for path, category in img_paths_and_categories]\r\n","    # create datasets\r\n","    train_val_border = int(split_factor*len(img_paths_and_categories))\r\n","    print(train_val_border, len(img_paths_and_categories))\r\n","    convert_dataset_to_h5(img_paths[:train_val_border], img_categories[:train_val_border], train_path, \"train\")\r\n","    convert_dataset_to_h5(img_paths[train_val_border:], img_categories[train_val_border:], val_path, \"val\")\r\n","       \r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["make_dataset_for_keras_h5(categories_and_paths, result_dir)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Make dataset from: {0: 'F:\\\\master-thesis-databases\\\\classification_db\\\\fake', 1: 'F:\\\\master-thesis-databases\\\\classification_db\\\\real'} to C:\\Users\\Marcin\\Dysk Google\\masterDB\n","8000 10000\n","To C:\\Users\\Marcin\\Dysk Google\\masterDB\\train.h5 for dataset:train\n","Saving images as X_train\n","Image number: 0\n","Image number: 100\n","Image number: 200\n","Image number: 300\n","Image number: 400\n","Image number: 500\n","Image number: 600\n","Image number: 700\n","Image number: 800\n","Image number: 900\n","Image number: 1000\n","Image number: 1100\n","Image number: 1200\n","Image number: 1300\n","Image number: 1400\n","Image number: 1500\n","Image number: 1600\n","Image number: 1700\n","Image number: 1800\n","Image number: 1900\n","Image number: 2000\n","Image number: 2100\n","Image number: 2200\n","Image number: 2300\n","Image number: 2400\n","Image number: 2500\n","Image number: 2600\n","Image number: 2700\n","Image number: 2800\n","Image number: 2900\n","Image number: 3000\n","Image number: 3100\n","Image number: 3200\n","Image number: 3300\n","Image number: 3400\n","Image number: 3500\n","Image number: 3600\n","Image number: 3700\n","Image number: 3800\n","Image number: 3900\n","Image number: 4000\n","Image number: 4100\n","Image number: 4200\n","Image number: 4300\n","Image number: 4400\n","Image number: 4500\n","Image number: 4600\n","Image number: 4700\n","Image number: 4800\n","Image number: 4900\n","Image number: 5000\n","Image number: 5100\n","Image number: 5200\n","Image number: 5300\n","Image number: 5400\n","Image number: 5500\n","Image number: 5600\n","Image number: 5700\n","Image number: 5800\n","Image number: 5900\n","Image number: 6000\n","Image number: 6100\n","Image number: 6200\n","Image number: 6300\n","Image number: 6400\n","Image number: 6500\n","Image number: 6600\n","Image number: 6700\n","Image number: 6800\n","Image number: 6900\n","Image number: 7000\n","Image number: 7100\n","Image number: 7200\n","Image number: 7300\n","Image number: 7400\n","Image number: 7500\n","Image number: 7600\n","Image number: 7700\n","Image number: 7800\n","Image number: 7900\n","To C:\\Users\\Marcin\\Dysk Google\\masterDB\\val.h5 for dataset:val\n","Saving images as X_val\n","Image number: 0\n","Image number: 100\n","Image number: 200\n","Image number: 300\n","Image number: 400\n","Image number: 500\n","Image number: 600\n","Image number: 700\n","Image number: 800\n","Image number: 900\n","Image number: 1000\n","Image number: 1100\n","Image number: 1200\n","Image number: 1300\n","Image number: 1400\n","Image number: 1500\n","Image number: 1600\n","Image number: 1700\n","Image number: 1800\n","Image number: 1900\n"]}],"metadata":{"tags":[]}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}